{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c40bb2-3cd0-44fe-9e9a-b2e1e8f0f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952b0c6c-7e82-4753-a5c0-26757c05e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "base_dir = r\"E:\\Tennis Schema\\data\\raw\"\n",
    "cache_file = \"cached_tables.pkl\"\n",
    "pd.options.io.parquet.engine = \"pyarrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97342580-16c2-4498-832b-83c4bc116fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loaded from cache.\n",
      "\n",
      " Summary of loaded tables:\n",
      "MatchEventInfo            → (16873, 10)\n",
      "MatchHomeTeamInfo         → (29262, 31)\n",
      "MatchAwayTeamInfo         → (28563, 31)\n",
      "MatchHomeScoreInfo        → (16873, 14)\n",
      "MatchAwayScoreInfo        → (16873, 14)\n",
      "MatchTournamentInfo       → (16873, 16)\n",
      "MatchSeasonInfo           → (16873, 4)\n",
      "MatchRoundInfo            → (9243, 5)\n",
      "MatchVenueInfo            → (16749, 5)\n",
      "MatchTimeInfo             → (16873, 7)\n",
      "OddsInfo                  → (28790, 11)\n",
      "GameInfo                  → (1254739, 13)\n",
      "StatisticInfo             → (665589, 13)\n",
      "PowerInfo                 → (230581, 5)\n",
      "MatchVotesInfo            → (16873, 3)\n",
      "\n",
      " All tables ready for analysis!\n",
      "Execution time =  1.5201992988586426\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(cache_file):\n",
    "    with open(cache_file, \"rb\") as f:\n",
    "        dfs = pickle.load(f)\n",
    "    print(\" Data loaded from cache.\")\n",
    "else:\n",
    "    dfs = {}\n",
    "\n",
    "    def read_parquet_group(folder, prefix, table_name):\n",
    "        \"\"\"Reads all parquet files in a folder that start with a specific prefix (parallel + safe).\"\"\"\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\" Folder not found: {folder_path}\")\n",
    "            return\n",
    "\n",
    "        parquet_files = [\n",
    "            os.path.join(folder_path, f)\n",
    "            for f in os.listdir(folder_path)\n",
    "            if f.startswith(prefix) and f.endswith(\".parquet\")\n",
    "        ]\n",
    "\n",
    "        if not parquet_files:\n",
    "            print(f\" No parquet files found for {table_name}\")\n",
    "            return\n",
    "\n",
    "        def load_one(path):\n",
    "            try:\n",
    "                return pd.read_parquet(path)\n",
    "            except Exception as e:\n",
    "                print(f\" Error reading {path}: {e}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "        max_workers = min(32, os.cpu_count() * 2)\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "            dfs_list = list(ex.map(load_one, parquet_files))\n",
    "\n",
    "        non_empty = [d for d in dfs_list if not d.empty]\n",
    "        if non_empty:\n",
    "            dfs[table_name] = pd.concat(non_empty, ignore_index=True)\n",
    "            print(f\" Loaded {table_name:25} → {dfs[table_name].shape}\")\n",
    "        else:\n",
    "            print(f\" No data in {table_name}\")\n",
    "\n",
    "    match_folder = \"raw_match_parquet\"\n",
    "    read_parquet_group(match_folder, \"event_\", \"MatchEventInfo\")\n",
    "    read_parquet_group(match_folder, \"home_team_\", \"MatchHomeTeamInfo\")\n",
    "    read_parquet_group(match_folder, \"away_team_\", \"MatchAwayTeamInfo\")\n",
    "    read_parquet_group(match_folder, \"home_team_score_\", \"MatchHomeScoreInfo\")\n",
    "    read_parquet_group(match_folder, \"away_team_score_\", \"MatchAwayScoreInfo\")\n",
    "    read_parquet_group(match_folder, \"tournament_\", \"MatchTournamentInfo\")\n",
    "    read_parquet_group(match_folder, \"season_\", \"MatchSeasonInfo\")\n",
    "    read_parquet_group(match_folder, \"round_\", \"MatchRoundInfo\")\n",
    "    read_parquet_group(match_folder, \"venue_\", \"MatchVenueInfo\")\n",
    "    read_parquet_group(match_folder, \"time_\", \"MatchTimeInfo\")\n",
    "\n",
    "    read_parquet_group(\"raw_odds_parquet\", \"odds_\", \"OddsInfo\")\n",
    "    read_parquet_group(\"raw_point_by_point_parquet\", \"pbp_\", \"GameInfo\")\n",
    "    read_parquet_group(\"raw_statistics_parquet\", \"statistics_\", \"StatisticInfo\")\n",
    "    read_parquet_group(\"raw_tennis_power_parquet\", \"power_\", \"PowerInfo\")\n",
    "    read_parquet_group(\"raw_votes_parquet\", \"votes_\", \"MatchVotesInfo\")\n",
    "\n",
    "    with open(cache_file, \"wb\") as f:\n",
    "        pickle.dump(dfs, f)\n",
    "\n",
    "print(\"\\n Summary of loaded tables:\")\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name:25} → {df.shape}\")\n",
    "\n",
    "print(\"\\n All tables ready for analysis!\")\n",
    "end = time.time()\n",
    "print(\"Execution time = \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45439ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19bb39cd",
   "metadata": {},
   "source": [
    "Q1:How many tennis player are included in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9bbaf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MatchHomeTeam=dfs['MatchHomeTeamInfo']\n",
    "df_MatchAwayTeam=dfs['MatchAwayTeamInfo']\n",
    "\n",
    "df_MatchAwayTeam['player_id']=df_MatchAwayTeam['player_id'].astype(str).str.strip()\n",
    "df_MatchHomeTeam['player_id']=df_MatchHomeTeam['player_id'].astype(str).str.strip()\n",
    "df_MatchAwayTeam = df_MatchAwayTeam[df_MatchAwayTeam['player_id'].notna()]\n",
    "df_MatchHomeTeam = df_MatchHomeTeam[df_MatchHomeTeam['player_id'].notna()]\n",
    "\n",
    "players = pd.concat([df_MatchAwayTeam['player_id'],\n",
    "                     df_MatchHomeTeam['player_id']]).drop_duplicates()\n",
    "\n",
    "len(players)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
